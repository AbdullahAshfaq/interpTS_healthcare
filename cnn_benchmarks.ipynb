{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Complexity metrics on all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 01:54:22.733184: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 01:54:22.740262: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 01:54:22.780765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-02 01:54:22.780795: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-02 01:54:22.780817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 01:54:22.792447: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 01:54:22.792967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-02 01:54:37.784535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from TSInterpret.InterpretabilityModels.Saliency.TSR import TSR, Saliency_PTY\n",
    "from TSInterpret.InterpretabilityModels.counterfactual.TSEvoCF import TSEvo\n",
    "# from TSInterpret.InterpretabilityModels.counterfactual.SETSCF import SETSCF\n",
    "\n",
    "import torch \n",
    "from XTSCBench.ClassificationModels.CNN_T import ResNetBaseline, UCRDataset,fit\n",
    "from XTSCBench.ClassificationModels.LSTM import LSTM\n",
    "from XTSCBench.CounterfactualEvaluation import CounterfactualEvaluation\n",
    "from tslearn.datasets import UCR_UEA_datasets\n",
    "import sklearn\n",
    "import numpy as np \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='Epilepsy'\n",
    "# dataset = 'ptbxl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if dataset in ['ECG200','ECG5000','Epilepsy']:\n",
    "    train_x, train_y, test_x, test_y=UCR_UEA_datasets().load_dataset(dataset)\n",
    "elif dataset == 'ptbxl':\n",
    "    train_x = np.load(f'./datasets/ptbxl/x_train.npy')\n",
    "    train_y = np.load(f'./datasets/ptbxl/y_train.npy')\n",
    "    test_x = np.load(f'./datasets/ptbxl/x_test.npy')\n",
    "    test_y = np.load(f'./datasets/ptbxl/y_test.npy')\n",
    "\n",
    "# 1 hot encoding outcomes\n",
    "enc1=sklearn.preprocessing.OneHotEncoder(sparse=False).fit(np.vstack((train_y.reshape(-1,1),test_y.reshape(-1,1))))\n",
    "train_y=enc1.transform(train_y.reshape(-1,1))\n",
    "test_y=enc1.transform(test_y.reshape(-1,1))    \n",
    "\n",
    "n_pred_classes =train_y.shape[1]\n",
    "NumTimesteps = train_x.shape[-2]\n",
    "NumFeatures = train_x.shape[-1]\n",
    "\n",
    "#For use with CNN reverse Data Dimensions\n",
    "# Note that (samples, timesteps, features) -> (samples, features, timesteps) for CNN models\n",
    "train_dataset = UCRDataset(train_x.astype(np.float64).reshape(-1,NumFeatures,NumTimesteps),train_y.astype(np.int64))\n",
    "test_dataset = UCRDataset(test_x.astype(np.float64).reshape(-1,NumFeatures,NumTimesteps),test_y.astype(np.int64))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 3, 206)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 206, 3), (137, 4), (138, 206, 3), (138, 4), 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, n_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 3, 206)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 206)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cpu'\n",
    "\n",
    "model_path = './trained_models'\n",
    "\n",
    "# Model saved by this name\n",
    "model_name = f'cnn_{dataset}'\n",
    "NumFeatures, NumTimesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cnn_Epilepsy successfully loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNetBaseline(\n",
       "  (layers): Sequential(\n",
       "    (0): ResNetBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(3, 64, kernel_size=(8,), stride=(1,))\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(64, 64, kernel_size=(5,), stride=(1,))\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(64, 64, kernel_size=(3,), stride=(1,))\n",
       "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Sequential(\n",
       "        (0): Conv1dSamePadding(3, 64, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNetBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(64, 128, kernel_size=(8,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(128, 128, kernel_size=(5,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(128, 128, kernel_size=(3,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (residual): Sequential(\n",
       "        (0): Conv1dSamePadding(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResNetBlock(\n",
       "      (layers): Sequential(\n",
       "        (0): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(128, 128, kernel_size=(8,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(128, 128, kernel_size=(5,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): ConvBlock(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1dSamePadding(128, 128, kernel_size=(3,), stride=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if os.path.isfile(f'./{model_path}/{model_name}'):\n",
    "    model = ResNetBaseline(in_channels=NumFeatures, num_pred_classes=n_pred_classes)\n",
    "    model = torch.load(f'./{model_path}/{model_name}')\n",
    "    print(f\"Model {model_name} successfully loaded\")\n",
    "else:\n",
    "    print(\"Model not found. Please train model using training_models.ipynb and provide in this notebook\")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y was one Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "from TSInterpret.InterpretabilityModels.counterfactual.TSEvoCF import TSEvo\n",
    "\n",
    "tsevo_exp = TSEvo(model= model,data=(train_x,train_y), mode = 'feat',backend='PYT',epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumTimesteps, NumFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Saliency \n",
    "\n",
    "## Methods\n",
    "# * Gradients (GRAD)\n",
    "# * Integrated Gradients (IG)\n",
    "# * Gradient Shap (GS)\n",
    "# * DeepLift (DL)\n",
    "# * DeepLiftShap (DLS)\n",
    "# * SmoothGrad (SG)\n",
    "# * Shapley Value Sampling(SVS)\n",
    "# * Feature Ablation (FA)\n",
    "# * Occlusion (FO)\n",
    "\n",
    "from TSInterpret.InterpretabilityModels.Saliency.TSR import TSR, Saliency_PTY\n",
    "\n",
    "tsr_GRAD_exp = Saliency_PTY(model, NumTimeSteps=NumTimesteps, NumFeatures=NumFeatures, method='GRAD', mode='feat', tsr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_FA_exp = Saliency_PTY(model, NumTimeSteps=NumTimesteps, NumFeatures=NumFeatures, method='FA', mode='feat', tsr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_FO_exp =  Saliency_PTY(model, NumTimeSteps=NumTimesteps, NumFeatures=NumFeatures, method='FO', mode='feat', tsr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NativeGuideCF\n",
    "# from TSInterpret.InterpretabilityModels.counterfactual.NativeGuideCF import NativeGuideCF\n",
    "\n",
    "# ng_exp = NativeGuideCF(model,(train_x,train_y), backend='PYT', mode='feat',method='NUN_CF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer =  [\n",
    "    tsevo_exp,\n",
    "    tsr_FA_exp,\n",
    "    tsr_GRAD_exp,\n",
    "    # tsr_FO_exp\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bm=CounterfactualEvaluation(explainer=explainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable = bm.evaluate(test_x[0:2], np.argmax(test_y[0:2],axis=1),model, mode='feat',aggregate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1_mean</th>\n",
       "      <th>d2_mean</th>\n",
       "      <th>d3_mean</th>\n",
       "      <th>d4_mean</th>\n",
       "      <th>validty_mean</th>\n",
       "      <th>d1_std</th>\n",
       "      <th>d2_std</th>\n",
       "      <th>d3_std</th>\n",
       "      <th>d4_std</th>\n",
       "      <th>validty_std</th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.749141</td>\n",
       "      <td>164.691622</td>\n",
       "      <td>4.681957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>32.029047</td>\n",
       "      <td>0.210359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d1_mean   d2_mean     d3_mean   d4_mean  validty_mean  d1_std    d2_std  \\\n",
       "0      1.0  0.749141  164.691622  4.681957           1.0     0.0  0.073618   \n",
       "\n",
       "      d3_std    d4_std  validty_std method normalize   tsr  \n",
       "0  32.029047  0.210359          0.0   GRAD      True  True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 2\n",
    "interp_folder = './interp_metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm=CounterfactualEvaluation(explainer=explainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Target\n",
      "No Target\n"
     ]
    }
   ],
   "source": [
    "SummaryTable_counterfact = bm.evaluate(test_x[0:num_test_samples], np.argmax(test_y[0:num_test_samples],axis=1),model, mode='feat',aggregate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1_mean</th>\n",
       "      <th>d2_mean</th>\n",
       "      <th>d3_mean</th>\n",
       "      <th>d4_mean</th>\n",
       "      <th>validty_mean</th>\n",
       "      <th>d1_std</th>\n",
       "      <th>d2_std</th>\n",
       "      <th>d3_std</th>\n",
       "      <th>d4_std</th>\n",
       "      <th>validty_std</th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "      <th>transformer</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.652476</td>\n",
       "      <td>467.489528</td>\n",
       "      <td>2.783514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.063659</td>\n",
       "      <td>113.706556</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999191</td>\n",
       "      <td>0.639725</td>\n",
       "      <td>475.515837</td>\n",
       "      <td>2.976765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>85.324344</td>\n",
       "      <td>0.295514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957929</td>\n",
       "      <td>0.329733</td>\n",
       "      <td>327.827550</td>\n",
       "      <td>3.935000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.141273</td>\n",
       "      <td>105.262107</td>\n",
       "      <td>1.265721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>authentic_opposing_information</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    d1_mean   d2_mean     d3_mean   d4_mean  validty_mean    d1_std    d2_std  \\\n",
       "0  0.998382  0.652476  467.489528  2.783514           1.0  0.002288  0.063659   \n",
       "1  0.999191  0.639725  475.515837  2.976765           1.0  0.001144  0.075973   \n",
       "2  0.957929  0.329733  327.827550  3.935000           1.0  0.002288  0.141273   \n",
       "\n",
       "       d3_std    d4_std  validty_std method normalize   tsr  \\\n",
       "0  113.706556  0.004901          0.0   GRAD      True  True   \n",
       "1   85.324344  0.295514          0.0     FA      True  True   \n",
       "2  105.262107  1.265721          0.0    NaN       NaN   NaN   \n",
       "\n",
       "                      transformer epochs  \n",
       "0                             NaN    NaN  \n",
       "1                             NaN    NaN  \n",
       "2  authentic_opposing_information     30  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable_counterfact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable_counterfact.to_csv(f\"{interp_folder}/{model_name}_CF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faithfulness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XTSCBench.FaithfulnessEvaluation import FaithfulnessEvaluation\n",
    "bm=FaithfulnessEvaluation(explainer=explainer,mlmodel=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET METRICS\n",
      "Original (2, 140, 1)\n",
      "EXP (2, 140, 1)\n",
      "Num features=140, Mode=feat\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 8], expected input[1, 140, 2] to have 1 channels, but got 140 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SummaryTable_faith \u001b[38;5;241m=\u001b[39m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/FaithfulnessEvaluation.py:49\u001b[0m, in \u001b[0;36mFaithfulnessEvaluation.evaluate\u001b[0;34m(self, items, label, model, meta, exp, explainer, generation, mode, aggregate)\u001b[0m\n\u001b[1;32m     47\u001b[0m exp_n\u001b[38;5;241m=\u001b[39mget_explanation(items, label, data_shape_1, data_shape_2, baseline, model,mode)\n\u001b[1;32m     48\u001b[0m exp_n\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(exp_n)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, data_shape_1,data_shape_2)\n\u001b[0;32m---> 49\u001b[0m row_summary\u001b[38;5;241m=\u001b[39m \u001b[43mget_faithfullness_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m aggregate:\n\u001b[1;32m     51\u001b[0m     df\u001b[38;5;241m=\u001b[39mparameters_to_pandas(baseline)\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/metrics/faithfulness_metrics.py:146\u001b[0m, in \u001b[0;36mget_faithfullness_metrics\u001b[0;34m(original, exp, mlmodel, labels, explainer, mode, additional_metrics, generation_process, subset_size)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# if num_feat<2:\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m         df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonoton_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmonoton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mperturb_baseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m#except:\u001b[39;00m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;66;03m#df[f'monoton_{a}']=  np.array(np.repeat(np.nan,len(original)))\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[1;32m    150\u001b[0m         df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaithfulness_correlation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m  np\u001b[38;5;241m.\u001b[39marray(faithfulnessCorrelelation(mlmodel,original,labels, exp,explainer,perturb_baseline\u001b[38;5;241m=\u001b[39ma, subset_size\u001b[38;5;241m=\u001b[39msubset_size))\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/metrics/faithfulness_metrics.py:79\u001b[0m, in \u001b[0;36mmonoton\u001b[0;34m(mod, data, label, res, exp, perturb_baseline, perturb_func)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m starts from a reference baseline to then incrementally replace each feature in a sorted attribution vector, measuring the effect on model performance \u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m#TODO Parameters\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     78\u001b[0m metrics \u001b[38;5;241m=\u001b[39m quantus\u001b[38;5;241m.\u001b[39mMonotonicity(  perturb_baseline\u001b[38;5;241m=\u001b[39mperturb_baseline, perturb_func\u001b[38;5;241m=\u001b[39mperturb_func,disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 79\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mexplain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/faithfulness/monotonicity.py:227\u001b[0m, in \u001b[0;36mMonotonicity.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    139\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    153\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    This implementation represents the main logic of the metric and makes the class object callable.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    It completes instance-wise evaluation of explanations (a_batch) with respect to input data (x_batch),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m        >> scores = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=a_batch_saliency}\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/base.py:225\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_instance_iterator(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_instance, data_instance \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m--> 225\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_results[id_instance] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Call custom post-processing.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/faithfulness/monotonicity.py:304\u001b[0m, in \u001b[0;36mMonotonicity.evaluate_instance\u001b[0;34m(self, model, x, y, a, s)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# Predict on perturbed input x (that was initially filled with a constant 'perturb_baseline' value).\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     x_input \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mshape_input(x_baseline, x\u001b[38;5;241m.\u001b[39mshape, channel_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 304\u001b[0m     y_pred_perturb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m[:, y])\n\u001b[1;32m    305\u001b[0m     preds[i_ix] \u001b[38;5;241m=\u001b[39m y_pred_perturb\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39mdiff(preds) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/helpers/model/pytorch_model.py:123\u001b[0m, in \u001b[0;36mPyTorchModel.predict\u001b[0;34m(self, x, grad, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m grad_context:\n\u001b[1;32m    122\u001b[0m     pred_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_softmax_arg_model()\n\u001b[0;32m--> 123\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mpred_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/ClassificationModels/CNN_T.py:67\u001b[0m, in \u001b[0;36mResNetBaseline.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/ClassificationModels/CNN_T.py:96\u001b[0m, in \u001b[0;36mResNetBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_channels:\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual(x)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/ClassificationModels/CNN_T.py:145\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/ClassificationModels/CNN_T.py:111\u001b[0m, in \u001b[0;36mConv1dSamePadding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv1d_same_padding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/ClassificationModels/CNN_T.py:123\u001b[0m, in \u001b[0;36mconv1d_same_padding\u001b[0;34m(input, weight, bias, stride, dilation, groups)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 8], expected input[1, 140, 2] to have 1 channels, but got 140 channels instead"
     ]
    }
   ],
   "source": [
    "SummaryTable_faith = bm.evaluate(test_x[0:num_test_samples], np.argmax(test_y[0:num_test_samples],axis=1), model, mode='feat',aggregate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method normalize   tsr\n",
       "0   GRAD      True  True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable_faith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "      <th>transformer</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>authentic_opposing_information</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method normalize   tsr                     transformer epochs\n",
       "0   GRAD      True  True                             NaN    NaN\n",
       "1     FA      True  True                             NaN    NaN\n",
       "2    NaN       NaN   NaN  authentic_opposing_information     30"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable_faith.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable_faith.to_csv(f\"{interp_folder}/{model_name}_faith.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings and information:\n",
      " (1) The AUC metric is likely to be sensitive to the choice of ground truth mask i.e., the 's_batch' input as well as if absolute values 'abs' are taken of the attributions .  \n",
      " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
      " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
      " (4) For further information, see original publication: Fawcett, Tom. 'An introduction to ROC analysis' Pattern Recognition Letters Vol 27, Issue 8, (2006).\n",
      " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from XTSCBench.ReliabilityEvaluation import ReliabilityEvaluation\n",
    "from quantus.metrics.localisation.auc import AUC\n",
    "\n",
    "bm=ReliabilityEvaluation(explainer=explainer,mlmodel=None, metrics=[AUC()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Target\n",
      "No Target\n"
     ]
    }
   ],
   "source": [
    "#CAREFUL THIS IS AN ASSUMPTION\n",
    "meta=np.zeros_like(test_x[0:num_test_samples])\n",
    "meta[:,10:20]= np.ones_like(meta[:,10:20])\n",
    "SummaryTable_reiable = bm.evaluate(test_x[0:num_test_samples], np.argmax(test_y[0:num_test_samples],axis=1),model,meta=meta,exp=None, mode='feat',aggregate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;quantus.metrics.localisation.auc.AUC object at 0x7fbd021032d0&gt;_mean</th>\n",
       "      <th>Pointing_mean</th>\n",
       "      <th>Relevance Rank_mean</th>\n",
       "      <th>Relevance Mass_mean</th>\n",
       "      <th>AuC_mean</th>\n",
       "      <th>&lt;quantus.metrics.localisation.auc.AUC object at 0x7fbd021032d0&gt;_std</th>\n",
       "      <th>Pointing_std</th>\n",
       "      <th>Relevance Rank_std</th>\n",
       "      <th>Relevance Mass_std</th>\n",
       "      <th>AuC_std</th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "      <th>transformer</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.047891</td>\n",
       "      <td>0.515505</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02357</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.046066</td>\n",
       "      <td>0.511990</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04714</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>FA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.712406</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.977226</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>authentic_opposing_information</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <quantus.metrics.localisation.auc.AUC object at 0x7fbd021032d0>_mean  \\\n",
       "0                                           0.515505                      \n",
       "1                                           0.511990                      \n",
       "2                                           0.622194                      \n",
       "\n",
       "   Pointing_mean  Relevance Rank_mean  Relevance Mass_mean  AuC_mean  \\\n",
       "0            0.0             0.050000             0.047891  0.515505   \n",
       "1            0.0             0.033333             0.046066  0.511990   \n",
       "2            0.0             0.066667            -0.712406  0.622194   \n",
       "\n",
       "   <quantus.metrics.localisation.auc.AUC object at 0x7fbd021032d0>_std  \\\n",
       "0                                           0.011344                     \n",
       "1                                           0.030144                     \n",
       "2                                           0.000601                     \n",
       "\n",
       "   Pointing_std  Relevance Rank_std  Relevance Mass_std   AuC_std method  \\\n",
       "0           0.0             0.02357            0.000871  0.011344   GRAD   \n",
       "1           0.0             0.04714            0.010573  0.030144     FA   \n",
       "2           0.0             0.00000            0.977226  0.000601    NaN   \n",
       "\n",
       "  normalize   tsr                     transformer epochs  \n",
       "0      True  True                             NaN    NaN  \n",
       "1      True  True                             NaN    NaN  \n",
       "2       NaN   NaN  authentic_opposing_information     30  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable_reiable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable_reiable.to_csv(f\"{interp_folder}/{model_name}_reliable.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings and information:\n",
      " (1) The Effective Complexity metric is likely to be sensitive to the choice of normalising 'normalise' (and 'normalise_func') and if taking absolute values of attributions 'abs' and the choice of threshold 'eps'.  \n",
      " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
      " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
      " (4) For further information, see original publication: Nguyen, An-phi, and María Rodríguez Martínez. 'On quantitative aspects of model interpretability.' arXiv preprint arXiv:2007.07584 (2020)..\n",
      " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from XTSCBench.ComplexityEvaluation import ComplexityEvaluation\n",
    "from quantus.metrics.complexity.effective_complexity import EffectiveComplexity\n",
    "\n",
    "bm=ComplexityEvaluation(explainer=explainer, metrics= [EffectiveComplexity()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Target\n",
      "No Target\n"
     ]
    }
   ],
   "source": [
    "SummaryTable_complex = bm.evaluate(test_x[0:num_test_samples], np.argmax(test_y[0:num_test_samples],axis=1), model, mode='feat',aggregate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity_mean</th>\n",
       "      <th>&lt;quantus.metrics.complexity.effective_complexity.EffectiveComplexity object at 0x7f89a761b350&gt;_mean</th>\n",
       "      <th>complexity_std</th>\n",
       "      <th>&lt;quantus.metrics.complexity.effective_complexity.EffectiveComplexity object at 0x7f89a761b350&gt;_std</th>\n",
       "      <th>method</th>\n",
       "      <th>normalize</th>\n",
       "      <th>tsr</th>\n",
       "      <th>transformer</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.361227</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.161484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GRAD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.330293</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.171294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.100786</td>\n",
       "      <td>617.0</td>\n",
       "      <td>0.045401</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>authentic_opposing_information</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complexity_mean  \\\n",
       "0         5.361227   \n",
       "1         5.330293   \n",
       "2         6.100786   \n",
       "\n",
       "   <quantus.metrics.complexity.effective_complexity.EffectiveComplexity object at 0x7f89a761b350>_mean  \\\n",
       "0                                              522.0                                                     \n",
       "1                                              522.0                                                     \n",
       "2                                              617.0                                                     \n",
       "\n",
       "   complexity_std  \\\n",
       "0        0.161484   \n",
       "1        0.171294   \n",
       "2        0.045401   \n",
       "\n",
       "   <quantus.metrics.complexity.effective_complexity.EffectiveComplexity object at 0x7f89a761b350>_std  \\\n",
       "0                                           0.000000                                                    \n",
       "1                                           0.000000                                                    \n",
       "2                                           1.414214                                                    \n",
       "\n",
       "  method normalize   tsr                     transformer epochs  \n",
       "0   GRAD      True  True                             NaN    NaN  \n",
       "1     FA      True  True                             NaN    NaN  \n",
       "2    NaN       NaN   NaN  authentic_opposing_information     30  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SummaryTable_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable_complex.to_csv(f\"{interp_folder}/{model_name}_complexity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XTSCBench.RobustnessEvaluation import RobustnessEvaluation\n",
    "\n",
    "bm=RobustnessEvaluation(explainer=explainer,mlmodel=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Target\n",
      "No Target\n",
      "Robustness Shapes\n",
      "(2, 96, 1)\n",
      "[1, 1]\n",
      "X1  (1, 96)\n",
      "y1  1\n",
      "No Target\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SummaryTable_robust \u001b[38;5;241m=\u001b[39m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/RobustnessEvaluation.py:52\u001b[0m, in \u001b[0;36mRobustnessEvaluation.evaluate\u001b[0;34m(self, items, label, model, exp, explainer, mode, aggregate)\u001b[0m\n\u001b[1;32m     50\u001b[0m label \u001b[38;5;241m=\u001b[39m get_preds(model, items)\n\u001b[1;32m     51\u001b[0m res\u001b[38;5;241m=\u001b[39mget_explanation(items, label, data_shape_1, data_shape_2, baseline, model,mode)\n\u001b[0;32m---> 52\u001b[0m row_summary\u001b[38;5;241m=\u001b[39m\u001b[43mget_robustness_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m aggregate:\n\u001b[1;32m     54\u001b[0m     df\u001b[38;5;241m=\u001b[39mparameters_to_pandas(baseline)\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/metrics/robustness_metrics.py:61\u001b[0m, in \u001b[0;36mget_robustness_metrics\u001b[0;34m(original, exp, mlmodel, labels, explainer, mode, additional_metrics)\u001b[0m\n\u001b[1;32m     59\u001b[0m explainer\u001b[38;5;241m=\u001b[39mQuantus_Wrapper(explainer, mode)\u001b[38;5;241m.\u001b[39mmake_callable\n\u001b[1;32m     60\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([])\n\u001b[0;32m---> 61\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverageSensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[43mAverageSensitivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     62\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxSensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(MaxSensitivity(mlmodel,original,labels, exp,explainer,channel_first))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additional_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/metrics/robustness_metrics.py:27\u001b[0m, in \u001b[0;36mAverageSensitivity\u001b[0;34m(mod, data, label, res, exp, channel_first)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mmeasures the average sensitivity of an explanation using a Monte Carlo sampling-based approximation \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     25\u001b[0m metric \u001b[38;5;241m=\u001b[39m quantus\u001b[38;5;241m.\u001b[39mAvgSensitivity(nr_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,lower_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, perturb_func\u001b[38;5;241m=\u001b[39mquantus\u001b[38;5;241m.\u001b[39muniform_noise, similarity_func\u001b[38;5;241m=\u001b[39mquantus\u001b[38;5;241m.\u001b[39mdifference,disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mexplain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/robustness/avg_sensitivity.py:254\u001b[0m, in \u001b[0;36mAvgSensitivity.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    166\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    This implementation represents the main logic of the metric and makes the class object callable.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    It completes instance-wise evaluation of explanations (a_batch) with respect to input data (x_batch),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m        >> scores = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=a_batch_saliency}\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoftmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_predict_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/base_batched.py:217\u001b[0m, in \u001b[0;36mBatchedMetric.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_batch \u001b[38;5;129;01min\u001b[39;00m batch_generator:\n\u001b[0;32m--> 217\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_results\u001b[38;5;241m.\u001b[39mextend(result)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Call post-processing.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/quantus/metrics/robustness/avg_sensitivity.py:337\u001b[0m, in \u001b[0;36mAvgSensitivity.evaluate_batch\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch)\u001b[0m\n\u001b[1;32m    331\u001b[0m     warn\u001b[38;5;241m.\u001b[39mwarn_perturbation_caused_no_change(\n\u001b[1;32m    332\u001b[0m         x\u001b[38;5;241m=\u001b[39mx_instance,\n\u001b[1;32m    333\u001b[0m         x_perturbed\u001b[38;5;241m=\u001b[39mx_instance_perturbed,\n\u001b[1;32m    334\u001b[0m     )\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# Generate explanation based on perturbed input x.\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m a_perturbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_func_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalise:\n\u001b[1;32m    345\u001b[0m     a_perturbed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalise_func(\n\u001b[1;32m    346\u001b[0m         a_perturbed,\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalise_func_kwargs,\n\u001b[1;32m    348\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/D_drive/UCSD/Quarters/Q4/DSC261-RespDS/ts_causal_wsl/lib/python3.11/site-packages/XTSCBench/metrics/metrics_helper.py:62\u001b[0m, in \u001b[0;36mQuantus_Wrapper.make_callable\u001b[0;34m(self, model, inputs, targets, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my1 \u001b[39m\u001b[38;5;124m'\u001b[39m, y1)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     a\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     64\u001b[0m         a,b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexplain(x1\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mint\u001b[39m(y1))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "SummaryTable_robust = bm.evaluate(test_x[0:2], np.argmax(test_y[0:2],axis=1), model,exp=None, mode='time',aggregate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryTable_robust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_causal_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
